(self.webpackChunkwebsite=self.webpackChunkwebsite||[]).push([[58],{3905:function(e,t,a){"use strict";a.d(t,{Zo:function(){return p},kt:function(){return f}});var n=a(7294);function r(e,t,a){return t in e?Object.defineProperty(e,t,{value:a,enumerable:!0,configurable:!0,writable:!0}):e[t]=a,e}function s(e,t){var a=Object.keys(e);if(Object.getOwnPropertySymbols){var n=Object.getOwnPropertySymbols(e);t&&(n=n.filter((function(t){return Object.getOwnPropertyDescriptor(e,t).enumerable}))),a.push.apply(a,n)}return a}function o(e){for(var t=1;t<arguments.length;t++){var a=null!=arguments[t]?arguments[t]:{};t%2?s(Object(a),!0).forEach((function(t){r(e,t,a[t])})):Object.getOwnPropertyDescriptors?Object.defineProperties(e,Object.getOwnPropertyDescriptors(a)):s(Object(a)).forEach((function(t){Object.defineProperty(e,t,Object.getOwnPropertyDescriptor(a,t))}))}return e}function i(e,t){if(null==e)return{};var a,n,r=function(e,t){if(null==e)return{};var a,n,r={},s=Object.keys(e);for(n=0;n<s.length;n++)a=s[n],t.indexOf(a)>=0||(r[a]=e[a]);return r}(e,t);if(Object.getOwnPropertySymbols){var s=Object.getOwnPropertySymbols(e);for(n=0;n<s.length;n++)a=s[n],t.indexOf(a)>=0||Object.prototype.propertyIsEnumerable.call(e,a)&&(r[a]=e[a])}return r}var l=n.createContext({}),c=function(e){var t=n.useContext(l),a=t;return e&&(a="function"==typeof e?e(t):o(o({},t),e)),a},p=function(e){var t=c(e.components);return n.createElement(l.Provider,{value:t},e.children)},d={inlineCode:"code",wrapper:function(e){var t=e.children;return n.createElement(n.Fragment,{},t)}},u=n.forwardRef((function(e,t){var a=e.components,r=e.mdxType,s=e.originalType,l=e.parentName,p=i(e,["components","mdxType","originalType","parentName"]),u=c(a),f=r,m=u["".concat(l,".").concat(f)]||u[f]||d[f]||s;return a?n.createElement(m,o(o({ref:t},p),{},{components:a})):n.createElement(m,o({ref:t},p))}));function f(e,t){var a=arguments,r=t&&t.mdxType;if("string"==typeof e||r){var s=a.length,o=new Array(s);o[0]=u;var i={};for(var l in t)hasOwnProperty.call(t,l)&&(i[l]=t[l]);i.originalType=e,i.mdxType="string"==typeof e?e:r,o[1]=i;for(var c=2;c<s;c++)o[c]=a[c];return n.createElement.apply(null,o)}return n.createElement.apply(null,a)}u.displayName="MDXCreateElement"},623:function(e,t,a){"use strict";a.r(t),a.d(t,{frontMatter:function(){return o},metadata:function(){return i},toc:function(){return l},default:function(){return p}});var n=a(2122),r=a(9756),s=(a(7294),a(3905)),o={},i={unversionedId:"examples/ner",id:"examples/ner",isDocsHomePage:!1,title:"NER Token Classification",description:"This is an example explaining entire pipeline for NER task using pymarlin library. You can bring your own data and write a similar NER task for your dataset.",source:"@site/docs/examples/ner.md",sourceDirName:"examples",slug:"/examples/ner",permalink:"/docs/examples/ner",editUrl:"https://github.com/microsoft/PyMarlin/edit/master/website/docs/examples/ner.md",version:"current",frontMatter:{},sidebar:"docsSidebar",previous:{title:"Glue Tasks",permalink:"/docs/examples/glue-tasks"},next:{title:"Stats and tensorboard",permalink:"/docs/utils/stats"}},l=[{value:"Configs - YAML and Parsing",id:"configs---yaml-and-parsing",children:[]},{value:"Implementing Data Interface",id:"implementing-data-interface",children:[{value:"DataModule",id:"datamodule",children:[]},{value:"Single process and Multi process dataProcessor",id:"single-process-and-multi-process-dataprocessor",children:[]}]},{value:"Train module and callback functions",id:"train-module-and-callback-functions",children:[]}],c={toc:l};function p(e){var t=e.components,a=(0,r.Z)(e,["components"]);return(0,s.kt)("wrapper",(0,n.Z)({},c,a,{components:t,mdxType:"MDXLayout"}),(0,s.kt)("p",null,"This is an example explaining entire pipeline for NER task using pymarlin library. You can bring your own data and write a similar NER task for your dataset."),(0,s.kt)("h2",{id:"configs---yaml-and-parsing"},"Configs - YAML and Parsing"),(0,s.kt)("p",null,"For ease of use we have configs passed in as YAML files.\nIn this case we use the config file : config_prod.yaml included with example code."),(0,s.kt)("p",null,"Snippet of config:"),(0,s.kt)("pre",null,(0,s.kt)("code",{parentName:"pre",className:"language-python"},'filename: "ner_dataset.csv"\ndist: False\ntrainRatio: 0.8\ntokenizer_type: "bert"\nmax_seq_length: 128\npad_label_id: -100\n\ntmgr:\n    train_batch_size: 32\n    val_batch_size: 32 # Validation global batch size.\n    epochs: 2 # Total epochs to run.\n    gpu_batch_size_limit : 32 # Max limit for GPU batch size during training.\n    disable_tqdm : False\n    writers: ["aml", "tensorboard"]\n')),(0,s.kt)("p",null,"This config can be read in like below : "),(0,s.kt)("pre",null,(0,s.kt)("code",{parentName:"pre",className:"language-python"},"#Create arg parser and read config\nparser = CustomArgParser(log_level='DEBUG', default_yamlfile=\"config_prod.yaml\")\nconfig = parser.parse()\n")),(0,s.kt)("p",null,"The filename in this case be accessed like this: config",'["filename"]','.\nAs we see above you can also create sub classes of configs like "tmgr" which can be used like config','["tmgr"]["trainRatio"]'),(0,s.kt)("h2",{id:"implementing-data-interface"},"Implementing Data Interface"),(0,s.kt)("p",null,"The data interface hosts the data Module and processors. DataModule is the orchestrator and each of the data processor is used implement a stage in the data preparation stage."),(0,s.kt)("h3",{id:"datamodule"},"DataModule"),(0,s.kt)("p",null,"The data module is the one which calls the processor's process function. There are 2 options"),(0,s.kt)("p",null,(0,s.kt)("strong",{parentName:"p"},"process_data(*args)")," : This function accepts arguments which will be passed on to the processor, this is made for 1 node and 1 process at a time."),(0,s.kt)("p",null,(0,s.kt)("strong",{parentName:"p"},"multi_process_data(*args,process_count)")," : This function is similar to process_data accepts the args atleast one of which should be of type list which needs to be used for multiprocessing.  multi_process_data can be run as is with multiple nodes with just process_count set if its being run in AML."),(0,s.kt)("p",null,"For non-AML scenarios with multi-node setting class DistributedPreprocessArguments needs to be initialized with relevant arguments"),(0,s.kt)("p",null,"In the NER scenario we have 2 data processors 1 for reading the files and processing sentences.\nThe second data processor to create featurized examples from the sentences which have been read."),(0,s.kt)("p",null,"Data Module:"),(0,s.kt)("pre",null,(0,s.kt)("code",{parentName:"pre",className:"language-python"},'class NER_dataModule(data_interface.DataInterface):\n    def __init__(self) -> None:\n        super(NER_dataModule, self).__init__()\n\n    def set_datasets(self, features):\n        self.train_dataset = BaseDataset(features["train"] ,isLabel = True)\n        self.val_dataset = BaseDataset(features["val"] ,isLabel = True)\n\n    def get_train_dataset(self):\n        return self.train_dataset\n\n    def get_val_dataset(self):   \n        return self.val_dataset\n\n    def get_test_dataset(self):\n')),(0,s.kt)("h3",{id:"single-process-and-multi-process-dataprocessor"},"Single process and Multi process dataProcessor"),(0,s.kt)("p",null,"The switch between single and multi process is seemless. "),(0,s.kt)("p",null,"data.py is a single process implementation whereas data_multi.py is the multi-process counterpart."),(0,s.kt)("p",null,"Single process: "),(0,s.kt)("pre",null,(0,s.kt)("code",{parentName:"pre",className:"language-python"},'#create and run processor1\nexample_processor = Processor1(config["filename"], config["trainRatio"])\nout = dataModule.process_data(example_processor)\n')),(0,s.kt)("p",null,"Multi process:"),(0,s.kt)("pre",null,(0,s.kt)("code",{parentName:"pre",className:"language-python"},'#create and run processor2\nfeature_processor = Processor2(config["tokenizer_type"], config["max_seq_length"], config["pad_label_id"], out)\nout2 = dataModule.multi_process_data(feature_processor, out["train"], process_count=10)\n')),(0,s.kt)("p",null,"Note: The only major restriction for multi_process is for atleast one of the arguments to be a list. A list of items/files/parameters which needs to be split to processes. Each process will call the data processor logic with a instance from the list."),(0,s.kt)("h2",{id:"train-module-and-callback-functions"},"Train module and callback functions"),(0,s.kt)("p",null,"The train module exposes callback functions where the scenario can add logic they would want to implement."),(0,s.kt)("pre",null,(0,s.kt)("code",{parentName:"pre",className:"language-python"},'class NERTrainModule(module_interface.ModuleInterface):\n    def __init__(\n        self,\n        data: NER_dataModule,\n        args: TrainModuleArgs\n    ):\n        super().__init__()\n\n\n    def reset(self):\n\n\n    def get_optimizers_schedulers(self, estimated_global_steps_per_epoch: int, epochs:int):\n\n\n    def get_train_dataloader(self, sampler: torch.utils.data.Sampler, batch_size: int):\n\n\n    def get_val_dataloaders(self, sampler: torch.utils.data.Sampler, batch_size: int):\n\n\n    def train_step(self, global_step: int, batch, device):\n\n\n    def val_step(self, global_step: int, batch, device):\n\n    \n    def on_end_train_epoch(self, global_step:int, *train_step_collated_outputs):\n        self.eval_loss, self.eval_accuracy = 0, 0\n        self.predictions , self.true_labels = np.array([]), np.array([])\n        self.mask = np.array([])\n    \n    def on_end_val_epoch(self, global_step, collated_loss, key="default"):\n        active = self.mask == 1\n        preds = self.predictions[active]\n        labs = self.true_labels[active]\n        print("Validation F1-Score: {}".format(f1_score(preds.tolist(), labs.tolist(), average=\'macro\')))\n        print("Validation Accuracy: {}".format(accuracy_score(preds.tolist(), labs.tolist())))\n')),(0,s.kt)("p",null,"In NER we add logic for train_step, val_step where we call the model and save the output back per step/batch. We also add logic for on_end_train_epoch, on_end_val_epoch which will be executed once the train/val epoch ends."),(0,s.kt)("p",null,"For example above you can see the logic to calculate metrics at the end of validation epoch. and saving running loss during training in on_end_train_epoch."))}p.isMDXComponent=!0}}]);