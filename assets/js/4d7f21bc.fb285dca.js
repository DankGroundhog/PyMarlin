(self.webpackChunkwebsite=self.webpackChunkwebsite||[]).push([[345],{3905:function(e,t,a){"use strict";a.d(t,{Zo:function(){return d},kt:function(){return m}});var n=a(7294);function r(e,t,a){return t in e?Object.defineProperty(e,t,{value:a,enumerable:!0,configurable:!0,writable:!0}):e[t]=a,e}function s(e,t){var a=Object.keys(e);if(Object.getOwnPropertySymbols){var n=Object.getOwnPropertySymbols(e);t&&(n=n.filter((function(t){return Object.getOwnPropertyDescriptor(e,t).enumerable}))),a.push.apply(a,n)}return a}function o(e){for(var t=1;t<arguments.length;t++){var a=null!=arguments[t]?arguments[t]:{};t%2?s(Object(a),!0).forEach((function(t){r(e,t,a[t])})):Object.getOwnPropertyDescriptors?Object.defineProperties(e,Object.getOwnPropertyDescriptors(a)):s(Object(a)).forEach((function(t){Object.defineProperty(e,t,Object.getOwnPropertyDescriptor(a,t))}))}return e}function i(e,t){if(null==e)return{};var a,n,r=function(e,t){if(null==e)return{};var a,n,r={},s=Object.keys(e);for(n=0;n<s.length;n++)a=s[n],t.indexOf(a)>=0||(r[a]=e[a]);return r}(e,t);if(Object.getOwnPropertySymbols){var s=Object.getOwnPropertySymbols(e);for(n=0;n<s.length;n++)a=s[n],t.indexOf(a)>=0||Object.prototype.propertyIsEnumerable.call(e,a)&&(r[a]=e[a])}return r}var l=n.createContext({}),p=function(e){var t=n.useContext(l),a=t;return e&&(a="function"==typeof e?e(t):o(o({},t),e)),a},d=function(e){var t=p(e.components);return n.createElement(l.Provider,{value:t},e.children)},u={inlineCode:"code",wrapper:function(e){var t=e.children;return n.createElement(n.Fragment,{},t)}},c=n.forwardRef((function(e,t){var a=e.components,r=e.mdxType,s=e.originalType,l=e.parentName,d=i(e,["components","mdxType","originalType","parentName"]),c=p(a),m=r,f=c["".concat(l,".").concat(m)]||c[m]||u[m]||s;return a?n.createElement(f,o(o({ref:t},d),{},{components:a})):n.createElement(f,o({ref:t},d))}));function m(e,t){var a=arguments,r=t&&t.mdxType;if("string"==typeof e||r){var s=a.length,o=new Array(s);o[0]=c;var i={};for(var l in t)hasOwnProperty.call(t,l)&&(i[l]=t[l]);i.originalType=e,i.mdxType="string"==typeof e?e:r,o[1]=i;for(var p=2;p<s;p++)o[p]=a[p];return n.createElement.apply(null,o)}return n.createElement.apply(null,a)}c.displayName="MDXCreateElement"},5070:function(e,t,a){"use strict";a.r(t),a.d(t,{frontMatter:function(){return o},metadata:function(){return i},toc:function(){return l},default:function(){return d}});var n=a(2122),r=a(9756),s=(a(7294),a(3905)),o={},i={unversionedId:"examples/glue-tasks",id:"examples/glue-tasks",isDocsHomePage:!1,title:"Glue Tasks",description:"You can use the pymarlin library to easily benchmark your models for the GLUE tasks.",source:"@site/docs/examples/glue-tasks.md",sourceDirName:"examples",slug:"/examples/glue-tasks",permalink:"/docs/examples/glue-tasks",editUrl:"https://github.com/microsoft/PyMarlin/edit/master/website/docs/examples/glue-tasks.md",version:"current",frontMatter:{},sidebar:"docsSidebar",previous:{title:"Distillation",permalink:"/docs/examples/distillation"},next:{title:"NER Token Classification",permalink:"/docs/examples/ner"}},l=[{value:"Data Preprocessing",id:"data-preprocessing",children:[]},{value:"Training",id:"training",children:[]}],p={toc:l};function d(e){var t=e.components,a=(0,r.Z)(e,["components"]);return(0,s.kt)("wrapper",(0,n.Z)({},p,a,{components:t,mdxType:"MDXLayout"}),(0,s.kt)("p",null,"You can use the ",(0,s.kt)("inlineCode",{parentName:"p"},"pymarlin")," library to easily benchmark your models for the GLUE tasks.\nThe following walkthrough references the source code located ",(0,s.kt)("a",{parentName:"p",href:"https://o365exchange.visualstudio.com/O365%20Core/_git/ELR?path=%2Fsources%2Fdev%2FSubstrateInferences%2Fpymarlin_Scenarios%2Fglue&version=GBu%2Felr%2Fdocumentation&_a=contents"},"here"),"."),(0,s.kt)("p",null,"This walkthrough will be focused on the GLUE RTE task, run on CPU, although the source code is setup to run 8 tasks (CoLA, SST-2, MRPC, STS-B, QQP, MNLI, QNLI, RTE) and can also be run on a VM or Azure ML with distributed training."),(0,s.kt)("pre",null,(0,s.kt)("code",{parentName:"pre"},"Download the RTE dataset and setup as below:\nroot\n|-- RTE\n    |-- train.tsv\n    |-- dev.tsv\n")),(0,s.kt)("h2",{id:"data-preprocessing"},"Data Preprocessing"),(0,s.kt)("p",null,(0,s.kt)("inlineCode",{parentName:"p"},"config.yaml")," contains all the arguments needed for data preprocessing. ",(0,s.kt)("inlineCode",{parentName:"p"},"data.py")," is the script for data preprocessing."),(0,s.kt)("pre",null,(0,s.kt)("code",{parentName:"pre",className:"language-python"},'# data-module arguments\ndmod:\n    input_dir : "" # provide path to data directory here, it should only contain files\n    output_dir : ""\n\n# data-processor args\ndproc:\n    task: null # specify the task name (e.g. RTE)\n    max_seq_len: 128\n    no_labels: False\n    set_type: null # specify "train" or "dev" depending on which dataset is being preprocessed\n    tokenizer: "bert-base-uncased" # huggingface tokenizer name\n')),(0,s.kt)("p",null,"You can override the default values in the config through CLI:"),(0,s.kt)("pre",null,(0,s.kt)("code",{parentName:"pre"},'Command for train.tsv:\n    $ python data.py --dmod.input_dir "RTE" --dmod.output_dir "processed_data/train" --dproc.task "RTE" --dproc.set_type "train"\nCommand for dev.tsv:\n    $ python data.py --dmod.input_dir "RTE" --dmod.output_dir "processed_data/dev" --dproc.task "RTE" --dproc.set_type "dev"\n\nroot\n|-- processed_data\n    |-- train\n        |-- train.tsv (pickle dump)\n    |-- dev\n        |-- dev.tsv\n')),(0,s.kt)("p",null,"Data preprocessing consists of the following steps:"),(0,s.kt)("ol",null,(0,s.kt)("li",{parentName:"ol"},(0,s.kt)("p",{parentName:"li"},"Reading the input tsv file to create ",(0,s.kt)("inlineCode",{parentName:"p"},"InputExample"),". This is done by ",(0,s.kt)("inlineCode",{parentName:"p"},"glue_processors.RTEProcessor"),"."),(0,s.kt)("pre",{parentName:"li"},(0,s.kt)("code",{parentName:"pre",className:"language-python"},'    class RteProcessor(GLUEBaseProcessor):\n        """Processor for the RTE data set (GLUE version)."""\n        def __init__(self, args):\n            super().__init__(args)\n            \n        def get_labels(self):\n            """See base class."""\n            return ["entailment", "not_entailment"]\n\n        def _create_examples(self, lines, set_type):\n            """Creates examples for the training and dev sets."""\n            examples = []\n            for (i, line) in enumerate(lines):\n                if i == 0:\n                    continue\n                guid = i\n                text_a = line[1]\n                text_b = line[2]\n                label = line[-1] if set_type != "test" else "entailment"\n                examples.append(\n                    InputExample(guid=guid, text_a=text_a, text_b=text_b, label=label))\n            return examples\n'))),(0,s.kt)("li",{parentName:"ol"},(0,s.kt)("p",{parentName:"li"},"Tokenizing the text data to create features required for the Bert model (convert ",(0,s.kt)("inlineCode",{parentName:"p"},"InputExample")," to ",(0,s.kt)("inlineCode",{parentName:"p"},"InputFeatures"),"). This is done by the ",(0,s.kt)("inlineCode",{parentName:"p"},"Featurizer")," processor written in data.py.\nBoth ",(0,s.kt)("inlineCode",{parentName:"p"},"RTEProcessor")," and ",(0,s.kt)("inlineCode",{parentName:"p"},"Featurizer")," are based on ",(0,s.kt)("inlineCode",{parentName:"p"},"pymarlin.core.data_interface.DataProcessor")," which provides an additional functionality for python multiprocessing. The ",(0,s.kt)("inlineCode",{parentName:"p"},"process")," method in these data processors executes the logic written by the user. The optional ",(0,s.kt)("inlineCode",{parentName:"p"},"analyze")," method is intended to compute user specified data stats."),(0,s.kt)("pre",{parentName:"li"},(0,s.kt)("code",{parentName:"pre"},"```python\n    class Featurizer(DataProcessor):\n        def __init__(self, args, labels_list, tokenizer=None):\n            self.args = args\n            self.label_map = {label: i for i, label in enumerate(labels_list)} if None not in labels_list else None\n            self.tokenizer = tokenizer\n\n        def process(self, examples, output_path, save_features=False):\n            self.features = []\n            for example in examples:\n                tokens =  tokenizer(example.text_a,\n                                    example.text_b,\n                                    max_length=self.args.max_seq_len,\n                                    padding='max_length',\n                                    truncation=True,\n                                    return_token_type_ids=True,\n                                    return_tensors='pt')\n\n                if example.label is not None:\n                    if self.label_map is not None: # classification task\n                        label = self.label_map[example.label]\n                    else: # regression task data processor returns labels list [None]\n                        label = float(example.label)\n                else: # labels not provided (only inference)\n                    label = None\n                self.features.append(InputFeatures(tokens.input_ids.squeeze().tolist(),\n                                            tokens.attention_mask.squeeze().tolist(),\n                                            tokens.token_type_ids.squeeze().tolist(),\n                                            label))\n            if save_features:\n                with open(output_path, 'wb') as f:\n                    pickle.dump(self.features, f)\n            return self.features\n\n        def analyze(self):\n            logger.info(f\"# of features processed = {len(self.features)}\")\n```\n"))),(0,s.kt)("li",{parentName:"ol"},(0,s.kt)("p",{parentName:"li"},"Setup your PyTorch Dataset that converts above features to tensors ready to be consumed by the model during training. This is done by ",(0,s.kt)("inlineCode",{parentName:"p"},"TaskDataset"),"."),(0,s.kt)("pre",{parentName:"li"},(0,s.kt)("code",{parentName:"pre",className:"language-python"},"    class TaskDataset(Dataset):\n        def __init__(self, datapath):\n            self.datapath = datapath\n            self.load_features()\n\n        def load_features(self):\n            with open(self.datapath, 'rb') as f:\n                self.features = pickle.load(f)\n                \n        def __len__(self):\n            return len(self.features)\n\n        def __getitem__(self, idx):\n            feature = self.features[idx]\n            return self._create_tensors(feature)\n        \n        def _create_tensors(self, feature):\n            input_ids = torch.tensor(feature.input_ids, dtype=torch.long)\n            input_mask = torch.tensor(feature.attention_mask, dtype=torch.long)\n            segment_ids = torch.tensor(feature.token_type_ids, dtype=torch.long)\n            tensor_dict = {'input_ids':input_ids, 'attention_mask': input_mask, 'token_type_ids': segment_ids}\n            if feature.label is not None:\n                if type(feature.label) == int:\n                    label_id = torch.tensor(feature.label, dtype=torch.long)\n                else:\n                    label_id = torch.tensor(feature.label, dtype=torch.float)\n                tensor_dict.update({'labels': label_id})\n            return tensor_dict\n"))),(0,s.kt)("li",{parentName:"ol"},(0,s.kt)("p",{parentName:"li"},(0,s.kt)("inlineCode",{parentName:"p"},"pymarlin.core.data_interface.DataInterface")," is a template to orchestrate the execution of various processors that user implements and also retrieves the implemented PyTorch Datasets (used to feed the DataLoader during training)."),(0,s.kt)("pre",{parentName:"li"},(0,s.kt)("code",{parentName:"pre",className:"language-python"},"    class TaskData(DataInterface):\n        def __init__(self, args):\n            super().__init__()\n            self.args = args\n\n        def create_dataset(self, datapath):\n            return TaskDataset(datapath)\n            \n        def get_train_dataset(self, trainpath):\n            return self.create_dataset(trainpath)\n            \n        def get_val_dataset(self, valpath):\n            return self.create_dataset(valpath)\n        \n        def get_test_dataset(self, testpath):\n            return self.create_dataset(testpath)\n")))),(0,s.kt)("h2",{id:"training"},"Training"),(0,s.kt)("p",null,(0,s.kt)("inlineCode",{parentName:"p"},"config.yaml")," also contains all the arguments needed for training. ",(0,s.kt)("inlineCode",{parentName:"p"},"train.py")," is the script for training. The model we will finetune is HuggingFace's ",(0,s.kt)("inlineCode",{parentName:"p"},"bert-base-uncased"),", specified through ",(0,s.kt)("inlineCode",{parentName:"p"},"model.hf_model"),". "),(0,s.kt)("pre",null,(0,s.kt)("code",{parentName:"pre"},'Command for training & validation:\n    $ python train.py --tmod.task "RTE" --tmod.trainpath "processed_data/train" --tmod.valpath "processed_data/dev" --tmod.output_dir "training_output"\nCommand for inference only:\n    $ python train.py --tmod.task "RTE" --tmod.valpath "processed_data/dev" --tmod.output_dir "inference_output"\n\nThe difference is that when doing inference/validation only, it does not need `tmod.trainpath`.\n')),(0,s.kt)("p",null,(0,s.kt)("inlineCode",{parentName:"p"},"pymarlin.core.module_interface.ModuleInterface")," is the building block that interacts with various components of ",(0,s.kt)("inlineCode",{parentName:"p"},"pymarlin.core")," library. This is the block that the user should implement for their task. For GLUE, the implemented TrainModule is called ",(0,s.kt)("inlineCode",{parentName:"p"},"Recipe"),". Note that the module inherits from ",(0,s.kt)("inlineCode",{parentName:"p"},"torch.nn")," so it can also act as the model you would like to train."),(0,s.kt)("p",null,"The key parts of ",(0,s.kt)("inlineCode",{parentName:"p"},"Recipe"),":"),(0,s.kt)("ol",null,(0,s.kt)("li",{parentName:"ol"},(0,s.kt)("p",{parentName:"li"},"Setting up dataloaders for training and validation. For GLUE, the training dataloader is actually a generator, wrapped by PyTorch Dataloader. We implemented a generator that yields batches per input file, which may be useful for non-GLUE tasks that may lead to Out of Memory errors if the entire dataset is loaded. This is not required, so you are free to use any PyTorch Dataloader that works for your data. "),(0,s.kt)("pre",{parentName:"li"},(0,s.kt)("code",{parentName:"pre",className:"language-python"},'    def get_train_dataloader(self, sampler, batch_size):\n        dl = FilesGenDataloader(self.args, self.datamodule, "train")\n        total_datacount = dl.get_datacount()\n        self.logger.info(f"Total training samples = {total_datacount}")\n        dl_gen = dl.get_dataloader(total_datacount, sampler, batch_size)\n        return dl_gen\n')),(0,s.kt)("p",{parentName:"li"},"The validation dataloader returns a dictionary of dataloaders where the key is the name of the file. This is useful for tasks which may need to do post-processing after validation (and all_gathering in the case of distributed inferencing) with the original data file. "),(0,s.kt)("pre",{parentName:"li"},(0,s.kt)("code",{parentName:"pre",className:"language-python"},'    def get_val_dataloaders(self, sampler, batch_size):\n        dl = FilesDictDataloader(self.args, self.datamodule, "val")\n        total_datacount = dl.get_datacount()\n        self.logger.info(f"Total validation samples = {total_datacount}")\n        dl_dict = dl.get_dataloader(sampler, batch_size)\n        return dl_dict\n'))),(0,s.kt)("li",{parentName:"ol"},(0,s.kt)("p",{parentName:"li"},"Provide optimizers and schedulers."),(0,s.kt)("pre",{parentName:"li"},(0,s.kt)("code",{parentName:"pre",className:"language-python"},"    param_optimizer = list(self.model.named_parameters())\n    no_decay = ['bias', 'LayerNorm.weight'] # bert also has LayerNorm.bias\n    optimizer_grouped_parameters = [\n        {'params': [p for n, p in param_optimizer if not any(nd in n for nd in no_decay)], 'weight_decay': 0.0},\n        {'params': [p for n, p in param_optimizer if any(nd in n for nd in no_decay)], 'weight_decay': 0.0}\n        ]\n    ### Using Huggingface optimizer & scheduler for glue ###\n    optimizer = AdamW(optimizer_grouped_parameters, lr=self.args.max_lr, eps=1e-8, betas=(0.9, 0.999))\n    training_steps = estimated_global_steps_per_epoch * epochs\n    warmup_steps =  self.args.warmup_prop * training_steps\n    self.logger.debug(f\"# of warmup steps = {warmup_steps}, # of training steps = {training_steps}\")\n    scheduler = get_linear_schedule_with_warmup(\n        optimizer,\n        num_warmup_steps=warmup_steps,\n        num_training_steps=training_steps\n    )\n"))),(0,s.kt)("li",{parentName:"ol"},(0,s.kt)("p",{parentName:"li"},"Setting up model and related items such as config as needed."),(0,s.kt)("pre",{parentName:"li"},(0,s.kt)("code",{parentName:"pre",className:"language-python"},"    self.model_config = AutoConfig.from_pretrained(self.args.model_args.hf_model)\n    if self.args.task.lower() == 'sts-b': # STS-B is a regression task\n        self.model_config.num_labels = 1\n    self.model = AutoModelForSequenceClassification.from_pretrained(self.args.model_args.hf_model, config=self.model_config)\n"))),(0,s.kt)("li",{parentName:"ol"},(0,s.kt)("p",{parentName:"li"},"Specify ",(0,s.kt)("inlineCode",{parentName:"p"},"train_step")," and ",(0,s.kt)("inlineCode",{parentName:"p"},"val_step")," based on the model you setup."),(0,s.kt)("pre",{parentName:"li"},(0,s.kt)("code",{parentName:"pre",className:"language-python"},"    def train_step(self, global_step, batch, device):\n        inputs = self._inputs_to_device(batch, device)\n        outputs = self.model.forward(**inputs)\n        loss = outputs.loss\n        return loss\n")),(0,s.kt)("p",{parentName:"li"},"For GLUE, we set up our ",(0,s.kt)("inlineCode",{parentName:"p"},"TaskDataset")," such that it creates a dictionary of tensors. This allows use to directly pass in the inputs to the model. The outputs of a HuggingFace model is a Dataclass. We recommend the practice of creating model outputs as a Dataclass so it's easily understood and accessed. While ",(0,s.kt)("inlineCode",{parentName:"p"},"train_step")," only returns the loss, you can choose which outputs to return in ",(0,s.kt)("inlineCode",{parentName:"p"},"val_step")," which can be used by callbacks later on."),(0,s.kt)("pre",{parentName:"li"},(0,s.kt)("code",{parentName:"pre",className:"language-python"},"    def val_step(self, global_step, batch, device):\n        inputs = self._inputs_to_device(batch, device)\n        outputs = self.model.forward(**inputs)\n        if outputs.loss is not None:\n            return outputs.loss, outputs.logits, inputs['labels']\n        else:\n            return outputs.logits\n"))),(0,s.kt)("li",{parentName:"ol"},(0,s.kt)("p",{parentName:"li"},"Use the callbacks to do post-processing. The most important callback for GLUE tasks is  ",(0,s.kt)("inlineCode",{parentName:"p"},"on_end_val_epoch")," which is where we compute metrics for the task. You can use ",(0,s.kt)("inlineCode",{parentName:"p"},"global_stats")," to easily create AML or Tensorboart charts."),(0,s.kt)("pre",{parentName:"li"},(0,s.kt)("code",{parentName:"pre",className:"language-python"},'    def on_end_val_epoch(self, global_step, *inputs, key="default"):\n        """\n        args contains all values returned by val_step all_gathered over all processes and all steps\n        """\n        if not self.args.no_labels:\n            losses, logits, labels = inputs\n            losses = torch.stack(losses).mean().item()\n            global_stats.update(key+\'/val_loss\', losses, frequent=False)\n            labels = torch.cat(labels).cpu().numpy()\n            logits = torch.stack(logits)\n            preds = torch.argmax(logits, dim=-1).view(-1).cpu().numpy()\n            assert len(preds) == len(labels)\n            metrics = glue_dict[self.args.task.lower()]["metric"](labels, preds)\n            for k in metrics:\n                global_stats.update(key+\'/val_\'+k, metrics[k])\n')))))}d.isMDXComponent=!0}}]);